# -*- coding: utf-8 -*-
"""NLP_EXP8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HMgml-m_-4RRJMgdMgvuEe6FqKb-Rw8f
"""

!pip install sentence-transformers

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('all-MiniLM-L6-v2')

sentences = [
    "This is an example sentence",
    "Each sentence is converted",
    "The quick brown fox jumps over the lazy dog.",
    "A quick brown fox jumps over a lazy dog.",
    "The cat sat on the mat."
]
sentence_embeddings = model.encode(sentences)
display(sentence_embeddings.shape)

similarity_scores = util.cos_sim(sentence_embeddings, sentence_embeddings)
display(similarity_scores)

import torch

print("Similarity scores:")
display(similarity_scores)

high_similarity_threshold = 0.7
print(f"\nSentence pairs with similarity scores above {high_similarity_threshold}:")
for i in range(len(sentences)):
    for j in range(i + 1, len(sentences)):
        if similarity_scores[i, j] > high_similarity_threshold:
            print(f"Sentence {i+1} and Sentence {j+1}: '{sentences[i]}' vs '{sentences[j]}' - Score: {similarity_scores[i, j]:.4f}")

low_similarity_threshold = 0.3
print(f"\nSentence pairs with similarity scores below {low_similarity_threshold}:")
for i in range(len(sentences)):
    for j in range(i + 1, len(sentences)):
        if similarity_scores[i, j] < low_similarity_threshold:
            print(f"Sentence {i+1} and Sentence {j+1}: '{sentences[i]}' vs '{sentences[j]}' - Score: {similarity_scores[i, j]:.4f}")

print("\nInterpretation of similarity scores:")
print("Scores close to 1 indicate high semantic similarity (sentences have very similar meanings).")
print("Scores close to 0 indicate low semantic similarity (sentences have different meanings).")
print("Scores between 0 and 1 indicate varying degrees of semantic relatedness.")